{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Azharpat/ML-CLASSIFICATION-Health_Insurance_Cross_Sell_Prediction/blob/main/AZHAR_PATEL_Health_Insurance_Cross_Sell_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Health Insurance Cross Sell Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -**Azhar Patel"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company An insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company.\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/Azharpat/ML-CLASSIFICATION-Health_Insurance_Cross_Sell_Prediction"
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the customers from past year will also be interested in Vehicle Insurance provided by the company. In order to predict whether the customer would be interested in Vehicle insurance, we have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required. \n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits. \n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule. \n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "\n",
        "# Importing Numpy & Pandas for data processing & data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import missingno as msno\n",
        "%matplotlib inline  \n",
        "\n",
        "\n",
        "# Importing  tools for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "#setting font size throughout the notebook\n",
        "plt.rcParams.update({'font.size': 14})\n",
        "\n",
        "# Importing libraries for hypothesis testing\n",
        "from scipy.stats import uniform\n",
        "from scipy.stats import norm\n",
        "from scipy.stats import chi2\n",
        "from scipy.stats import t\n",
        "from scipy.stats import f\n",
        "\n",
        "# Importing libraries for data pre-processing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Importing Machine Learning algorithm libraries\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Importing Classification algorithm metrics\n",
        "from sklearn import metrics\n",
        "from mlxtend.plotting import plot_confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "plt.rcParams.update({'font.size': 14})"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "Zov7l3XLSBAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/drive/MyDrive/AZHAR PATEL Health_Insurance_Cross_Sell_Prediction/DATA/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv\")\n"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head()"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "8BjP6SLdT_E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "df.shape"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values=df.isna().sum()\n",
        "missing_values"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "missing_values.plot(kind='bar')"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Health insurance data has 381109 observation and 12 variables.their is no null value and duplicate value prsent in dataset."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description "
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Id: Unique ID for the custome\n",
        "\n",
        "Gender: Gender of the customer.\n",
        "\n",
        "Age: Age of the customer.\n",
        "\n",
        "Driving License: 0, customer does not have DL; 1, customer already has DL.\n",
        "\n",
        "Region Code: Unique code for the region of the customer.\n",
        "\n",
        "Previously Insured: 1, customer already has vehicle insurance; 0, customer doesn't have vehicle insurance.\n",
        "\n",
        "Vehicle Age: Age of the vehicle.\n",
        "\n",
        "Vehicle Damage: 1, customer got his/her vehicle damaged in the past; 0, customer didn't get his/her vehicle damaged in the past.\n",
        "\n",
        "Anual Premium: The amount customer needs to pay as premium in the year.\n",
        "\n",
        "Policy sales channel: Anonymized Code for the channel of outreaching to the\n",
        "\n",
        "customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n",
        "\n",
        "Vintage: Number of Days, customer has been associated with the company.\n",
        "\n",
        "Response: 1, customer is interested; 0, customer is not interested."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'categorical_columns' is a list of the column names that contain categorical variables\n",
        "\n",
        "for column in df.columns:\n",
        "    unique_values = df[column].unique()\n",
        "    unique_count = len(unique_values)\n",
        "    print(f\"The number of unique variables in {column} column is: {unique_count}\")\n",
        "\n",
        "    if unique_count <= 3:\n",
        "        if df[column].dtype.name in ['object', 'category'] or column in df.columns:\n",
        "            print(f\"Printing unique values of {column}: {unique_values.tolist()}\")\n",
        "        else:\n",
        "            print(f\"Printing unique values of {column}: {unique_values}\")\n"
      ],
      "metadata": {
        "id": "KDkE7BkWc1hj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# Having a copy of the dataframe(can be used if any manipulation on the orignal df is done)\n",
        "copy_df = df.copy()"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dropping the id column\n",
        "df.drop(['id'],axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ezCoElvwt_zf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting 'Driving_License' & 'Previously_Insured' from 1,0 to Yes and No using lambda function\n",
        "df['Driving_License'] = df['Driving_License'].apply(lambda x: 'Yes' if x==1 else \"No\")\n",
        "df['Previously_Insured']=df['Previously_Insured'].apply(lambda x: 'Yes' if x==1 else \"No\")"
      ],
      "metadata": {
        "id": "fobtjAxFt_m3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame\n",
        "columns_to_convert = ['Region_Code', 'Annual_Premium', 'Policy_Sales_Channel']\n",
        "\n",
        "# Convert columns from float to int\n",
        "df[columns_to_convert] = df[columns_to_convert].astype(int)\n"
      ],
      "metadata": {
        "id": "pMUdCnHkwZmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "k470v3bs_jCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Dropped the id column as it was irrelevant\n",
        "\n",
        "2. Converted the values in categorical columns 'Driving_License' & 'Previously_Insured' from 1 & 0 to Yes and No for better visualization.\n",
        "\n",
        "3. Coverted 'Region_Code' , 'Annual_Premium' & 'Policy_Sales_Channel' columns from float to int datatype to make it space optimized."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "# plotting count plot\n",
        "sns.countplot(x=df['Gender'], data=df)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('male and female customers proportion')\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.Gender.value_counts())"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose the count plot as a visualization because it is suitable for representing the distribution and comparison of categorical variables, such as the 'Gender' column in your DataFrame."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows that there are more male customers than female customers. The ratio of male to female customers is approximately 1.19, which means that there is about 1.19 male customers for every female customer."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the gained insights can help create a positive business impact. For example, if a company knows that there are more male customers than female customers, it can focus its marketing efforts on male customers. This can lead to an increase in sales and revenue. Additionally, the company can offer different products or services to male and female customers, depending on their needs and interests. This can also lead to an increase in sales and revenue."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "qGNMqEw2Yi7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "sns.countplot(x='Previously_Insured', data=df, hue = 'Response')\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Customers who previously insured and their response')\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.Previously_Insured.value_counts())"
      ],
      "metadata": {
        "id": "lHzIylHTYi7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "U5duhNDTYi7W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "NHCAiqb_Yi7X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "wg0aDiFaYi7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is observed that people who have previously not insured are intrested in the policy"
      ],
      "metadata": {
        "id": "3vRKxa9dYi7Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "bsGUe3QCYi7a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that people who have not insured previously are more intrested in buying the ploicy, so it is better to tap the market who previously have not insured"
      ],
      "metadata": {
        "id": "8YP0OjtKYi7b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3\n"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "sns.countplot(x='Driving_License', data=df)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Customers who own Driving License or not proportion')\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.Driving_License.value_counts())"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are 380297 people who own Driving License and 812 don't"
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its found that most of the people who own driving license owns a car"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "vm9gcvamY0LS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "sns.countplot(x='Vehicle_Damage', data=df, hue = 'Response')\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Vehicle Damage previously and customer\\'s response')\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.Vehicle_Damage.value_counts())"
      ],
      "metadata": {
        "id": "VKAreRLIY0L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "BIIFKj2iY0L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "Wi7--ZA2Y0L6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "UPkk5kMHY0L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its found that previously customers who got their vehicle damaged are more intrested in buying new policy"
      ],
      "metadata": {
        "id": "4ufojgL-Y0L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "AYEMAolTY0L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. customers who are previously not damaged their car are not much intrested in buying the policy\n",
        "2. people who have damaged their car previously are more intrested in buying the policy."
      ],
      "metadata": {
        "id": "b_M_vAt_Y0L7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "fA62iKOuZdS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "spread = df['Vehicle_Damage'].value_counts()\n",
        "plt.rcParams['figure.figsize'] = (5,5)\n",
        "\n",
        "# pictdistance 0.6 is set to display the value inside the chart, if set more than 1, it'll display outside the chart.\n",
        "spread.plot(kind = 'pie', autopct='%1.2f%%', pctdistance=0.6)\n",
        "\n",
        "#setting colum chart title\n",
        "plt.title(f'Damage vs not damage')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xy9qy8rmZdTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "8vH96-1ZZdTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie charts are easy to interpret and understand the logic and share of values better in percentage."
      ],
      "metadata": {
        "id": "TJQjA4CaZdTC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "K9h24uRyZdTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that people who have damaged their vehicle and not damaged share almost equal proportion."
      ],
      "metadata": {
        "id": "aCNaSvHoZdTF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "e2x4IABVZdTG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "comparing the insights previously it is found that the people who damaged their vehicle are more intrested to buy ploicy, so since 50% of the people who are willing to buy the plociy, the market is big to capture"
      ],
      "metadata": {
        "id": "2FyM_yBTZdTH"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyTINfmmZ3FP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6\n",
        "Vehicle age and customer response"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "\n",
        "sns.countplot(x='Vehicle_Age', data=df, hue = 'Response')\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Vehicle age and customer\\'s response')\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n",
        "# printing the counts for reference\n",
        "print(df.Vehicle_Age.value_counts())"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. It is observed that most of the people with vehicle age is 1-2 years.\n",
        "2. ratio wise people with vehicle age greater than 2 years are more intrested in buying policy\n",
        "3. most of the customers have their vehicle age as 1-2 years"
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "as per the ratio it is better to tap the customers whose vehicle age is more than 2 years and we have a good scope in people who own vehicle of age 1-2 years as well."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "AlYx-2zVaRva"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "plt.figure(figsize=(6,6))\n",
        "sns.boxplot(df['Age'])"
      ],
      "metadata": {
        "id": "Qd3sFSSYaRvc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "tOepaeBWaRve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Box plot chart helps in getting an all-round view. and see if there are any outliers"
      ],
      "metadata": {
        "id": "oMEMBlamaRvf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "f1HA6i1DaRvh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no outliers in the age columns and most of the customers belong to age group 25-48"
      ],
      "metadata": {
        "id": "kosYxtX9aRvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "cqEH40ZCaRvj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are no outliers in our data for the age column."
      ],
      "metadata": {
        "id": "l4QBPUkqaRvk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "drigx92Hac-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "plt.rcParams['figure.figsize'] = (20, 5)\n",
        "plt.hist(df['Annual_Premium'], bins = 50, color='red', edgecolor='black')\n",
        "\n",
        "plt.xlabel('Annual Premium')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Histplot for Annual Premium')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RIWZ4fglac_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "wg4pO8Ckac_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histogram chart shows the histogram for Anual premium"
      ],
      "metadata": {
        "id": "CAtGzNviac_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "64sdGsC6ac_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the premium falls under range 5000-100000"
      ],
      "metadata": {
        "id": "xs0uPFX6ac_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PqdiBjLbac_F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there are some premiums that are above 100000"
      ],
      "metadata": {
        "id": "QruD4iWuac_F"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tAB76mXFay9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "w0jOOxJtazYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "sns.set_style('darkgrid')\n",
        "plt.figure(figsize=(20, 5))\n",
        "\n",
        "sns.countplot(x='Region_Code', data=df)\n",
        "\n",
        "plt.title('Number of customers with respect to various Region code')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Number of Customers')"
      ],
      "metadata": {
        "id": "aUoCWsOHazYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "9-i4FLJRazYW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "KcwuDhdxazYX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "1Tj5WlJQazYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Most of the customers belong to region code 28 followed by 8"
      ],
      "metadata": {
        "id": "7Sj38VJUazYY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "LvZUAekwazYZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It helps us to understand that most of our customers belong to region code 28, so it would be better if we run our marketing campagn such that in 28 to aquire more customers and in other regions to penetrate the market."
      ],
      "metadata": {
        "id": "Ecf6eCUnazYZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5EKYgkL0a7x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "VXPx9AI8a8LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "# sns.countplot(x='Age',hue='Response',palette=\"mako\", data=df)\n",
        "\n",
        "# # setting chart title\n",
        "# plt.title('Various age of customer and their response')\n",
        "\n",
        "# # display chart\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "age_response = df.groupby(['Age', 'Response']).size().unstack()\n",
        "\n",
        "#plotting\n",
        "total_counts = age_response.sum(axis=1)\n",
        "age_response_ratios = age_response.div(total_counts, axis=0) * 100\n",
        "\n",
        "# create a stacked bar chart\n",
        "age_response_ratios.plot(kind='bar', stacked=True)\n",
        "plt.title('Percentage of people with different age and their response ratio')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Percentage')\n",
        "plt.legend(title='Response')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Sm3DqiR2a8LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "hvOA34iSa8LZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A stacked bar plot shows the percentage for all ages and their response"
      ],
      "metadata": {
        "id": "TiScbFlVa8LZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "646NdVd_a8La"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customes of age between 32-58 ar more mature and are intrested in buying the policy"
      ],
      "metadata": {
        "id": "c4qC7teMa8Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Zl_yAR74a8Lb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tapping the customer of age between 32-58 would be more benificial"
      ],
      "metadata": {
        "id": "fR1IChNHa8Lb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VcumwrDfb8bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "haBwpD16b8vg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "plt.figure(figsize=(7,3))\n",
        "plt.xlabel('Annual Premium')\n",
        "plt.ylabel('Density')\n",
        "\n",
        "ax=sns.distplot(np.sqrt(df['Annual_Premium']), color=\"y\")\n",
        "ax.axvline(np.sqrt(df['Annual_Premium']).mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
        "ax.axvline(np.sqrt(df['Annual_Premium']).median(), color='black', linestyle='dashed', linewidth=2)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6xsjC1rjb8vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1aop7N1Eb8vk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ditribution chart shows the ditributon of the Annual Premium"
      ],
      "metadata": {
        "id": "NNO0nRnSb8vl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "mXafiTbmb8vm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we found the mean and median distribution of the Anuall Premium"
      ],
      "metadata": {
        "id": "DfwV2sIKb8vn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "aJdJ1Fd0b8vo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "mean and median are nearly equal on the Annual Premium"
      ],
      "metadata": {
        "id": "yIzJV2Vjb8vq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HRNd1K8PcCT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "xc1lkE5TcKBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "data = df['Vehicle_Age'].value_counts()\n",
        "labels = [ '1-2 Year', '< 1 Year','> 2 Years'] \n",
        "\n",
        "#create pie chart\n",
        "plt.figure(figsize=(6,6))\n",
        "# explode=(0,0.1,0.1,0.1,0.0,1.3) explode=explode,\n",
        "color = ['r', 'c', 'g', 'm', 'k']\n",
        "plt.pie(data,  colors = color, autopct='%.2f%%',labels = labels, textprops={'fontsize': 18})\n",
        "plt.title('Vehicle Age')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# print(data)\n",
        "\n",
        "# delete the data\n",
        "del data\n"
      ],
      "metadata": {
        "id": "I4x1QKh8cKCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "6mN3rTHtcKCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pie plots are usually best for sharing visually distribution of data"
      ],
      "metadata": {
        "id": "c21EHcBTcKCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "VqG228KucKCq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its found that most of the customer have vehicle age of around 1-2 year and there are less customers whose vehicle age is greater than 2 years"
      ],
      "metadata": {
        "id": "m9PiAGcacKCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "01MfSIGbcKCs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insites are useful for understanding which age group customer's vehicles belongs to."
      ],
      "metadata": {
        "id": "V5Mjn1QecKCs"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ySIhhoGPcOrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "ArNST-2rcS3X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "sns.countplot(x='Driving_License',hue='Response', data=df)\n",
        "\n",
        "# setting chart title\n",
        "plt.title('Holding Driving license and customer\\'s response')\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# display chart\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "MqGEPRL6cS4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iRvbno4NcS4I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Count plot is well suited for finding the counts and plotting the count values."
      ],
      "metadata": {
        "id": "zBtkUSHFcS4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tYvqf8aEcS4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its found that most of the customers who do not own driving license are less and are least intreasted, so tapping the customers with license would be benificial"
      ],
      "metadata": {
        "id": "5ASUKRdEcS4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact? \n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "HsWv5fA6cS4J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Its found that most of the customers who do not own driving license are less and are least intreasted, so tapping the customers with license would be benificial"
      ],
      "metadata": {
        "id": "0hfZy8vBcS4J"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ar6VmMzVcfiR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "dtl0yHfXcf3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(15,8))\n",
        "# Plot heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='inferno')\n",
        "\n",
        "#setting labels to infer the plot\n",
        "plt.title('Correlation Matrix heatmap')\n",
        "plt.ylabel('Feature/Property')\n",
        "plt.xlabel('Feature/Property')"
      ],
      "metadata": {
        "id": "3iM0wunRcf3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "dmANIsQ4cf3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The corelation chart shows the relation between the two specific feature"
      ],
      "metadata": {
        "id": "bxtltcsQcf3f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "MFARuCObcf3g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is found that policy sales channel and respons is negativly correlated.\n",
        "\n",
        "most of the properties/features against eachother are very least correlated.\n"
      ],
      "metadata": {
        "id": "_dtibwtScf3i"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66yVPZwCck7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot "
      ],
      "metadata": {
        "id": "rOqjZtFyclNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code\n",
        "\n",
        "# since the data is extreemly high, plotting a pair plot would be time consuming, so we are taking a random sample of 25000 and creating subset\n",
        "# this can be still reduced by reducing the sample size\n",
        "df_sample = df.sample(n=25000, random_state=48)\n",
        "\n",
        "# plotting pair plot for the sample database\n",
        "# setting corner=True can still to reduce computation time, corner=True\n",
        "sns.pairplot(df_sample, diag_kind=\"kde\", kind = 'reg', hue = 'Response')\n",
        "\n",
        "\n",
        "#setting labels to infer the plot\n",
        "plt.title('Pair Plot')\n",
        "plt.ylabel('Feature/Property')\n",
        "plt.xlabel('Feature/Property')\n",
        "\n",
        "# delete sample data\n",
        "del df_sample"
      ],
      "metadata": {
        "id": "aJHRGeNiclNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "_UBS-ad3clNz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pair plots are used to show relationship between various variables\n",
        "\n",
        "Pair plots can also help us explore the distribution of variables in your dataset."
      ],
      "metadata": {
        "id": "EcOTz5l5clN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "7WTD4v53clN0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive response of Vintage customers are positivly correlated with annual customers\n",
        "\n",
        "policy sales channel is negativly corellated to age.\n"
      ],
      "metadata": {
        "id": "EayAjEyIclN1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.The average annual premium for a vehicle insurance is greater than 15,000.\n",
        "\n",
        "2.The average age of the customer is greater than 32.\n",
        "\n",
        "3.The Standard deviation of annual premium is 10,000.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average annual premium for a vehicle insurance is greater than 15,000.\n",
        "\n",
        "Null hypothesis H0: Average Annual premium not > 15,000.\n",
        "\n",
        "Alternate hypothesis Ha: Average Annual premium > 15,000."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "sYzZ_N8X_-WD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "annual_premium_sample = df['Annual_Premium'].sample(1000)\n",
        "annual_premium_mean = np.mean(annual_premium_sample)\n",
        "annual_premium_std = np.std(annual_premium_sample)\n",
        "\n",
        "print(annual_premium_mean)\n",
        "print(annual_premium_std)\n",
        "\n",
        "# Set the hypothesized mean\n",
        "hypothesized_mean = 1503\n",
        "\n",
        "# Set the sample size\n",
        "sample_size = 1000\n",
        "\n",
        "# Calculate the t-statistic\n",
        "t_statistic = (annual_premium_mean - hypothesized_mean) / (annual_premium_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate the degrees of freedom\n",
        "degrees_of_freedom = sample_size - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - t.cdf(np.abs(t_statistic), degrees_of_freedom))\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Make a decision\n",
        "if p_value < alpha:\n",
        "    print('The difference is statistically significant.')\n",
        "else:\n",
        "    print('The difference is not statistically significant.')"
      ],
      "metadata": {
        "id": "t0mJUxxcxKYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code you provided is performing a one-sample t-test to obtain the p-value."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In summary, the code is conducting a one-sample t-test to determine if there is evidence to reject the null hypothesis that the population mean is equal to 1503. The obtained p-value is used to make the decision."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average age of the customer is greater than 32.\n",
        "\n",
        "Null hypothesis H0: Average age not > 32.\n",
        "\n",
        "Alternate hypothesis Ha: Average age > 32."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "43BDtus2AxQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Get the sample\n",
        "age_sample = df['Age'].sample(1000)\n",
        "print(age_sample)\n",
        "\n",
        "# Calculate the mean and standard deviation of the sample\n",
        "age_mean = np.mean(age_sample)\n",
        "age_std = np.std(age_sample)\n",
        "\n",
        "# Set the hypothesized mean\n",
        "hypothesized_mean = 30  # Replace with your specific hypothesized mean\n",
        "\n",
        "# Set the sample size\n",
        "sample_size = 1000\n",
        "\n",
        "# Calculate the t-statistic\n",
        "t_statistic = (age_mean - hypothesized_mean) / (age_std / np.sqrt(sample_size))\n",
        "\n",
        "# Calculate the degrees of freedom\n",
        "degrees_of_freedom = sample_size - 1\n",
        "\n",
        "# Calculate the p-value\n",
        "p_value = 2 * (1 - t.cdf(np.abs(t_statistic), degrees_of_freedom))\n",
        "\n",
        "print(p_value)\n",
        "\n",
        "# Set the significance level\n",
        "alpha = 0.05\n",
        "\n",
        "# Make a decision\n",
        "if p_value < alpha:\n",
        "    print('The difference is statistically significant.')\n",
        "else:\n",
        "    print('The difference is not statistically significant.')\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "the statistical test used to obtain the p-value is a one-sample t-test. "
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The conclusion of the code is that the mean age of the sample is significantly different from the hypothesized mean of 30. This means that there is a less than 5% chance that the difference is due to chance. Therefore, we can conclude that the mean age of the sample is significantly different from the hypothesized mean."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Standard deviation of annual premium is 10,000.\n",
        "\n",
        "Null hypothesis H0: Standard deviation != 10,000.\n",
        "\n",
        "Alternate hypothesis Ha: Standard deviation = 10,000."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2\n",
        "import scipy.stats as stats\n",
        "# Get the sample\n",
        "premium_sample = df['Annual_Premium'].sample(50)\n",
        "\n",
        "# Calculate the sample variance\n",
        "sample_variance = np.var(premium_sample, ddof=1)  # ddof=1 for unbiased estimator\n",
        "\n",
        "# Compute the test statistic\n",
        "test_statistic = (49 * sample_variance) / (10000*10000)\n",
        "\n",
        "# Calculate the probability\n",
        "probability = 1 - stats.chi2.cdf(test_statistic, 49)\n",
        "\n",
        "print(\"Test Statistic:\", test_statistic)\n",
        "print(\"Probability:\", probability)\n"
      ],
      "metadata": {
        "id": "xZdglvEfT3ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code performs a chi-square test for variance. "
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chi-square test is used to determine whether there is a significant difference between the observed variance in a sample and a hypothesized variance."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L8qI4UuV-nsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "eK8kjyoppax6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values\n",
        "(no missing values)"
      ],
      "metadata": {
        "id": "tayXf_alpayR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation"
      ],
      "metadata": {
        "id": "bdbRmhqspayR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "XqIvyx2EpayS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "---9iiDxpayS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "ax80IPUupayS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "#after investigating we found most of the outliers in Annual Premium\n",
        "\n",
        "\n",
        "# Plotting the boxplot for 'Annual_Premium'\n",
        "sns.boxplot(x=df['Annual_Premium'])\n",
        "plt.xlabel('values')\n",
        "plt.ylabel('Annual Premium')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9jw2Jn9ipayT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding interquantile range\n",
        "\n",
        "percentile25 = df['Annual_Premium'].quantile(0.25)\n",
        "percentile75 = df['Annual_Premium'].quantile(0.75)\n",
        "iqr = percentile75 - percentile25\n",
        "upper_limit = percentile75 + 1.5 * iqr\n",
        "lower_limit = percentile25 - 1.5 * iqr\n",
        "\n",
        "print(f'upper limit = {upper_limit} \\nlower limit = {lower_limit}')"
      ],
      "metadata": {
        "id": "omlganEF-Srl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Capping\n",
        "# Capping the data above the upper limit to upper limit & below the lower limit to the lower limit\n",
        "\n",
        "df['Annual_Premium'] = np.where(\n",
        "    df['Annual_Premium'] > upper_limit,\n",
        "    upper_limit,\n",
        "    np.where(\n",
        "        df['Annual_Premium'] < lower_limit,\n",
        "        lower_limit,\n",
        "        df['Annual_Premium']\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "PYMOlAI6-aNk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the boxplot again to check if the capping is correct\n",
        "sns.boxplot(x=df['Annual_Premium'])\n",
        "plt.xlabel('values')\n",
        "plt.ylabel('Annual Premium')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1nk-3CK9-0-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7-1p98UZpayV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**'Capping'** method is used to treat outliers. As there are 3,81,109 entries in the dataset and trimming the outliers shall lose lot of data."
      ],
      "metadata": {
        "id": "rKVDJIBYpayV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "yvb-jlTNpayV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df=pd.get_dummies(df,drop_first=True,sparse=True)"
      ],
      "metadata": {
        "id": "95m4uArjpayW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "xrzcYYC3payW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using one hot encoding and dropping the first column(drop_first=True) so that we get all the data in int format for easy machine learning."
      ],
      "metadata": {
        "id": "qAX6heMMpayW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing \n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "DQCeUDfcpayX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "MdZQR2ZmpayX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "qoRUS10gpayX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "2pvcdwgJpayX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "EQ4FQjafpayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "4X0B8XFNpayY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "EYkgHqjlpayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "bylV7ZvVpayZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2D_rZqCmpayZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "GWpPEGdKpayZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "nkfyywakpayZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "zM39jkULpaya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "Py1B2A_qpaya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "lKPWWwHSpaya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "rClsd9sDpaya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "XGmIi-0gpayb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "CEYLwpPNpayb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "dNWZjBh8payb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "IWiPCdIDpayb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "pWoXnjQ1payc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "c6pDGNIMpayc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "l4NbQqzjpayc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "oxpUbmHwpayc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "trhZpUohpayc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "-ZYQUFizpayd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "snVXLqPKpayd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "p4A3_Ihdpayd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "eOxAzhMPpayd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "MWRwKiGXAVHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = df.corr()\n",
        "plt.figure(figsize=(15,8))\n",
        "# Plot heatmap\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='inferno')\n",
        "\n",
        "#setting labels to infer the plot\n",
        "plt.title('Correlation Matrix heatmap')\n",
        "plt.ylabel('Feature/Property')\n",
        "plt.xlabel('Feature/Property')"
      ],
      "metadata": {
        "id": "6zGy-ZgyAc-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection\n",
        "do not offer insurance to people who do not own a license"
      ],
      "metadata": {
        "id": "fNamiyyFpaye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "#we see there is 0.01 correlation between dirviing licence and response.\n",
        "# logically we see that its pretty obvious we do not offer insurance to people who do not own a license, so this column is irrelavant.\n",
        "\n",
        "# dropping the Driving Licence Yes column.\n",
        "df.drop(columns=['Driving_License_Yes'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "brfETNTepayf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "soZx6sGLpayf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropped the Driving_License_Yes column, other columns are equally important"
      ],
      "metadata": {
        "id": "HyJO1g0cpayg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "u3JLJrUtpayg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refering to the correlation plot, we see that the columns are correlated not high nor low, Driving_License_Yes was less correlated so it is dropped."
      ],
      "metadata": {
        "id": "9ZqS6L0ypayg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation\n",
        "(not required in this case)"
      ],
      "metadata": {
        "id": "STBilPilpayh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "C4-VFAjRpayh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data"
      ],
      "metadata": {
        "id": "IdaMec6npayi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling\n",
        "(performed this step after train and test data split)"
      ],
      "metadata": {
        "id": "_24vFY6kpayi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "8-NAxLf7payi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "U37_2vI0payj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction\n",
        "(not needed)"
      ],
      "metadata": {
        "id": "uh76jUYLpayj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "3RnL3B-hpayj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "76fMvblbpayj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "K3wxWyngpayk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "1e7j2d2Apayk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qa-W7Pitpayk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting\n",
        "(spliting after balancing the data)"
      ],
      "metadata": {
        "id": "wAiAgilypayl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n"
      ],
      "metadata": {
        "id": "FuC3dtC1payl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why? "
      ],
      "metadata": {
        "id": "K9YoDWAcpaym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UZ83nGJkpaym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "H0_fjHJwpaym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "8guGd5n6paym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Response we have more response as 0 compare to 1. so the dataset is known as imbalanced dataset.\n",
        "\n",
        "In a classification problem, the goal is to accurately predict the class or category of a given input data point. The accuracy of the classification model is highly dependent on the distribution of classes in the dataset. A dataset is said to be balanced if the number of samples in each class is roughly equal.\n",
        "\n",
        "In case of an imbalanced dataset, the model tends to be biased towards the majority class, resulting in poor performance on the minority class."
      ],
      "metadata": {
        "id": "4jo-g-rUpayn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Defining X(independent variables) and y(response) variable\n",
        "\n",
        "X=df.drop(['Response'],axis=1)\n",
        "y=df['Response']\n",
        "print('Before OverSampling')\n",
        "print(\"counts of label '1': {}\".format(sum(y == 1))) \n",
        "print(\"counts of label '0': {}\".format(sum(y == 0))) "
      ],
      "metadata": {
        "id": "ZdtJOtQXEJSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# Using SMOTE method\n",
        "\n",
        "smote_var=SMOTE()\n",
        "x_balanced, y_balanced = smote_var.fit_resample(X, y.ravel()) # y.ravel() is used to flatten the y array. ravel() converts it into a 1D array of shape (n_samples,).\n",
        "\n",
        "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_balanced == 1))) \n",
        "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_balanced == 0))) \n"
      ],
      "metadata": {
        "id": "UsLPEDX6EZa2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the balanced dataset\n",
        "\n",
        "plt.figure(figsize = (15,5))\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x=df['Response'], data=df, palette='pastel')\n",
        "plt.title('Before sampling',fontsize=20)\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x=y_balanced,palette='pastel')\n",
        "plt.title('After sampling',fontsize=20)\n",
        "plt.xlabel('Response')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DobQ2OKnFQPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "qXPd4x20payo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have used smote to balance\n",
        "\n",
        "SMOTE (Synthetic Minority Oversampling Technique) works by randomly picking a point from the minority class and computing the k-nearest neighbors for this point. The synthetic points are added between the chosen point and its neighbors."
      ],
      "metadata": {
        "id": "f9V87wOypayo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train test split our data\n",
        "\n",
        "X_train,X_test,y_train,y_test = train_test_split(x_balanced,y_balanced, test_size=0.2,random_state=21)"
      ],
      "metadata": {
        "id": "tujO2bwYD71M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing the Dataset using Standard Scaling Technique.\n",
        "\n",
        "scaler=StandardScaler()\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "X_test=scaler.transform(X_test)\n",
        "print(X_train.shape,y_train.shape)\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "metadata": {
        "id": "Oeras2rdFgCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fhkPudZHAp8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "n4nuQYwNpiOm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = {}\n",
        "after_tuning_results = {}"
      ],
      "metadata": {
        "id": "_pWoWrPwsqqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_stat(model, X_train, X_test, y_train, y_test, output_name):\n",
        "  '''this function implements the given model calculates the stastics and add the results to dictionary\n",
        "  '''\n",
        "  # fit the model\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  # predicting the test model\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # predict probability\n",
        "  y_pred_probability = model.predict_proba(X_test)[:,1]\n",
        "  print('--'*30)\n",
        "  print(f'scores for {output_name}')\n",
        "  print('--'*30)\n",
        "  \n",
        "  # calculating the recall score on y test and y predict\n",
        "  recall_score_rs= recall_score(y_test, y_pred)\n",
        "  print(\"Recall_Score : \", recall_score_rs)\n",
        "  \n",
        "  # calculating the Precision Score\n",
        "  precision_score_ps= precision_score(y_test, y_pred)\n",
        "  print(\"Precision Score :\",precision_score_ps)\n",
        "\n",
        "  # calculating the f1 Score\n",
        "  f1_score_fs= f1_score(y_test, y_pred)\n",
        "  print(\"f1_Score :\", f1_score_fs)\n",
        "\n",
        "  # calculating the accuracy Score\n",
        "  accuracy_score_as= accuracy_score(y_test , y_pred)\n",
        "  print(\"Accuracy_Score :\",accuracy_score_as)\n",
        "\n",
        "  # Calculating the ROC auc Score\n",
        "  roc_auc_score_ras = roc_auc_score(y_test , y_pred)\n",
        "  print(\"ROC_AUC Score:\",roc_auc_score_ras)\n",
        "\n",
        "  # storing the results\n",
        "  results[output_name] = recall_score_rs, precision_score_ps, f1_score_fs, accuracy_score_as, roc_auc_score_ras\n",
        "\n",
        "  # getting confusion matrix\n",
        "  confusion_matrix_logic = metrics.confusion_matrix(y_test, y_pred)\n",
        "  print('--'*30)\n",
        "  print(f'confusion matrix for the implemented {output_name}')\n",
        "  print('--'*30)\n",
        "  print(confusion_matrix_logic)\n",
        "  print('\\n')\n",
        "\n",
        "  # Plotting the confusion matrix\n",
        "  fig, ax = plot_confusion_matrix(conf_mat=confusion_matrix_logic, figsize=(6, 6), cmap=plt.cm.Blues)\n",
        "  plt.xlabel('Predictions', fontsize=18)\n",
        "  plt.ylabel('Actuals', fontsize=18)\n",
        "  plt.title(f'Confusion Matrix for {output_name}', fontsize=18)\n",
        "  plt.show()\n",
        "\n",
        "  print('--'*30)\n",
        "  print(f'{output_name} ROC curve')\n",
        "  print('--'*30)\n",
        "\n",
        "  # Plotting ROC (Receiver Operating Characteristic) curve\n",
        "  plt.rcParams['figure.figsize'] = (6,6)\n",
        "  fpr, tpr, _ = roc_curve(y_test, y_pred_probability)\n",
        "  plt.title(f'{output_name} ROC curve')\n",
        "  plt.xlabel(\"False Positive Rate\")\n",
        "  plt.ylabel(\"True Positive Rate\")\n",
        "  plt.plot(fpr,tpr)\n",
        "  plt.plot((0,1), linestyle=\"--\",color='black')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1OFqz50egjKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1\n",
        "logistic regression"
      ],
      "metadata": {
        "id": "qOcMBpAjpiOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "# initiating the logistic regression\n",
        "LoReg = LogisticRegression()\n",
        "\n",
        "# Fit the Algorithm and Predict on the model\n",
        "get_stat(LoReg, X_train, X_test, y_train, y_test, 'Logistic Regression')\n"
      ],
      "metadata": {
        "id": "AtY3ytzRpiOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "nwKvt9h0piOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart"
      ],
      "metadata": {
        "id": "qZ8ll9lVpiOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "LAYn9DVrpiOp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "#setting grid parameters\n",
        "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "# Fit the Algorithm and Predict on the model\n",
        "grid_LoReg = GridSearchCV(LoReg, param_grid, cv=5)\n",
        "\n",
        "\n",
        "# getting scores after gridsearchCV\n",
        "get_stat(grid_LoReg, X_train, X_test, y_train, y_test, 'Logistic Regression after tuning')\n",
        "print('--'*30)\n",
        "print(\"Best cross-validation score:\", grid_LoReg.best_score_)\n",
        "print(\"Best parameters:\", grid_LoReg.best_params_)"
      ],
      "metadata": {
        "id": "vyvdEJyspiOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "9Zhsl_7OpiOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV** performs an exhaustive search over a specified hyperparameter space, creating a grid of all possible hyperparameter combinations, and evaluating the performance of each combination using cross-validation. It then selects the combination of hyperparameters that results in the best performance on the validation set.\n",
        "\n",
        "Using GridSearchCV can **save time and effort in the process of selecting hyperparameters** because it automates the process of evaluating different combinations of hyperparameters, eliminating the need for manual tuning. Additionally, it reduces the risk of overfitting, as it performs cross-validation on each combination of hyperparameters, ensuring that the selected hyperparameters generalize well to new data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The following code performs hyperparameter tuning on a logistic regression model using cross-validation:\n",
        "\n",
        "The param_grid dictionary specifies the hyperparameters to tune, which in this case is the regularization parameter C.\n",
        "\n",
        "GridSearchCV is used to perform a grid search over the specified hyperparameters.\n",
        "\n",
        "cv=5 specifies a 5-fold cross-validation.\n",
        "The hyperparameter that gives the best cross-validation score is selected as the optimal hyperparameter for the model."
      ],
      "metadata": {
        "id": "Wa-9_VMRpiOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ca6oF2UepiOr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is first implementation, however later we found random forest gives less false negative compare to this model.\n"
      ],
      "metadata": {
        "id": "Y4ZpnMQSpiOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2\n",
        "Random Forest Classifier"
      ],
      "metadata": {
        "id": "H5jQULjJpiOs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "t_QfAfhnpiOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# initializing rfc\n",
        "rfc = RandomForestClassifier()\n",
        "# geting stastics\n",
        "get_stat(rfc, X_train, X_test, y_train, y_test, 'Random Forest')"
      ],
      "metadata": {
        "id": "Ev6YWlcNpiOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "qfOwDhlDpiOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "rfc_tuned = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
        "                       criterion='gini', max_depth=30, max_features='log2',\n",
        "                       max_leaf_nodes=40, max_samples=None,\n",
        "                       min_impurity_decrease=0.0,\n",
        "                       min_samples_leaf=1, min_samples_split=4,\n",
        "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
        "                       n_jobs=None, oob_score=False, random_state=None,\n",
        "                       verbose=0, warm_start=False)\n",
        "\n",
        "# Fit the Algorithm and Predict on the model\n",
        "get_stat(rfc_tuned, X_train, X_test, y_train, y_test, 'random forest after tuning')"
      ],
      "metadata": {
        "id": "BCbNbd_IpiOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "ci7ur8afpiOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following hyperparameters tuning has been done in the RandomForestClassifier:\n",
        "\n",
        "bootstrap=True: Whether bootstrap samples are used when building trees.\n",
        "\n",
        "ccp_alpha=0.0: Complexity parameter used for Minimal Cost-Complexity Pruning.\n",
        "\n",
        "criterion='gini': The function to measure the quality of a split.\n",
        "\n",
        "max_depth=30: The maximum depth of the tree.\n",
        "\n",
        "max_features='log2': The number of features to consider when looking for the best split.\n",
        "\n",
        "max_leaf_nodes=40: The maximum number of leaf nodes in the tree.\n",
        "\n",
        "max_samples=None: The number of samples to draw from X to train each base estimator.\n",
        "\n",
        "min_impurity_decrease=0.0: A node will be split if this split induces a decrease of the impurity greater than or equal to this value.\n",
        "\n",
        "min_samples_leaf=1: The minimum number of samples required to be at a leaf node.\n",
        "\n",
        "min_samples_split=4: The minimum number of samples required to split an internal node.\n",
        "\n",
        "min_weight_fraction_leaf=0.0: The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node.\n",
        "n_estimators=200: The number of trees in the forest.\n",
        "\n",
        "n_jobs=None: The number of jobs to run in parallel for both fit and predict. None means 1 unless in a joblib.parallel_backend context.\n",
        "\n",
        "oob_score=False: Whether to use out-of-bag samples to estimate the generalization accuracy.\n",
        "\n",
        "random_state=None: Control the randomness of the estimator.\n",
        "\n",
        "verbose=0: Controls the verbosity when fitting and predicting.\n",
        "\n",
        "warm_start=False: When set to True, reuse the solution of the previous call to fit and add more estimators to the ensemble, otherwise, just fit a whole new forest."
      ],
      "metadata": {
        "id": "O54OAfQMpiOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "iWF_KK7vpiOv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is improvement in the model comparing to the Logistic regression.\n",
        "\n",
        "the false positive is more in logistic regression(7107) compare to random forest(5947) Random forest is providing better solution to the business. "
      ],
      "metadata": {
        "id": "tiH-F7mOpiOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "uY5GDSBrpiOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall_Score :  0.9170881340715248\n",
        "\n",
        "Precision_Score : 0.7752605747824327\n",
        "\n",
        "f1_Score : 0.8402314135694995\n",
        "\n",
        "Accuracy_Score : 0.8257476076555024\n",
        "\n",
        "ROC_AUC Score: 0.8258158435186549"
      ],
      "metadata": {
        "id": "ChyUD2ObpiOw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3\n",
        "XGBClassifier"
      ],
      "metadata": {
        "id": "JlMMV7WOpiOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "\n",
        "# Fit the Algorithm and Predict\n",
        "get_stat(xgb, X_train, X_test, y_train, y_test, 'XGB Classifier')"
      ],
      "metadata": {
        "id": "L-t9f-A5piOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "cS0IG6aMpiOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# done using the stat function"
      ],
      "metadata": {
        "id": "JSxN18LJpiOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "nGIxdw94piOx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "params = {\n",
        "    'max_depth': [3, 5],\n",
        "    'learning_rate': [0.1],\n",
        "    'n_estimators': [10, 20],\n",
        "}\n",
        "\n",
        "# Perform cross-validation and hyperparameter tuning\n",
        "grid_search_cv_xgb = GridSearchCV(xgb, params, cv=5, scoring='accuracy')\n",
        "# Fit the Algorithm and Predict on the model\n",
        "get_stat(grid_search_cv_xgb, X_train, X_test, y_train, y_test, 'XGB Classifier after tuning')\n"
      ],
      "metadata": {
        "id": "CzV-VMJlpiOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "l1P1eaxBpiOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GridSearchCV** performs an exhaustive search over a specified hyperparameter space, creating a grid of all possible hyperparameter combinations, and evaluating the performance of each combination using cross-validation. It then selects the combination of hyperparameters that results in the best performance on the validation set.\n",
        "\n",
        "Using GridSearchCV can **save time and effort in the process of selecting hyperparameters** because it automates the process of evaluating different combinations of hyperparameters, eliminating the need for manual tuning. Additionally, it reduces the risk of overfitting, as it performs cross-validation on each combination of hyperparameters, ensuring that the selected hyperparameters generalize well to new data.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "The following code is performing hyperparameter tuning for an XGBoost classifier using GridSearchCV. It is searching for the best combination of hyperparameters from the given parameter grid:\n",
        "\n",
        "max_depth: maximum depth of a tree.\n",
        "\n",
        "learning_rate: learning rate (shrinkage) used in each boosting step.\n",
        "\n",
        "n_estimators: number of boosting rounds (i.e., number of trees in the forest).\n",
        "\n",
        "The code is using 5-fold cross-validation to evaluate the performance of each hyperparameter combination and the accuracy scoring metric. The resulting best hyperparameters will be used to train the final XGBoost model."
      ],
      "metadata": {
        "id": "o5zHon7upiOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ch4J5FUjpiOy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing to Random forest, XGB is performing better\n",
        "\n",
        "false negative of XGB is more compare to random forest, hence this model would result a good cout to the business problem"
      ],
      "metadata": {
        "id": "gJ2aiP7ypiOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "8-qaVVTMpiOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall_Score would bw a better metrics as we do not want to miss on the customers who were intrested to by the policy and we miss them."
      ],
      "metadata": {
        "id": "0wnSkKKXpiOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "aFiHEAe5piOz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGB classifier after tuning is better with f1 score and the precession score is improved so it is better to go with this"
      ],
      "metadata": {
        "id": "-rNwLj9JpiO0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "-eazJHQXpiO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# features = x_balanced.columns\n",
        "# importances = grid_search_cv_xgb.feature_importances_\n",
        "# indices = np.argsort(importances)"
      ],
      "metadata": {
        "id": "MlivjrU6_xbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = x_balanced.columns\n",
        "importances = grid_search_cv_xgb.best_estimator_.feature_importances_\n",
        "indices = np.argsort(importances)[::-1]\n"
      ],
      "metadata": {
        "id": "vQPv-OYjttw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sort features by importance score in descending order\n",
        "sorted_features = [features[i] for i in indices]\n",
        "sorted_importances = importances[indices]\n",
        "\n",
        "# Create a DataFrame with sorted feature importances\n",
        "feature_importances = pd.DataFrame({'Feature': sorted_features, 'Importance': sorted_importances})\n",
        "# feature_importances = pd.DataFrame({'Feature': sorted_features, 'Importance': sorted_importances})\n",
        "\n"
      ],
      "metadata": {
        "id": "lsYjv7e_ui7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_importances = pd.DataFrame({'Feature': x_balanced.columns, 'Importance': importances})\n",
        "\n",
        "# sort the DataFrame by importance score in descending order\n",
        "feature_importances = feature_importances.sort_values('Importance', ascending=False)\n"
      ],
      "metadata": {
        "id": "DvbmtVbTQQJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting figure\n",
        "plt.figure(figsize=(6,6))\n",
        "plt.title('Importance of Feature')\n",
        "plt.barh(y=feature_importances['Feature'], width=feature_importances['Importance'])\n",
        "\n",
        "# plt.barh(range(len(indices)), importances[indices], color='green', align='center')\n",
        "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
        "plt.xlabel('Relative Importance')\n",
        "\n",
        "plt.show()\n",
        "     "
      ],
      "metadata": {
        "id": "UWlZg2kQABeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see from the feature importance graph, the feature 'Previously_Insured_yes' can be considered as most important with relative importance of 0.38. \n",
        "\n",
        "The next 4 features are vintage, annual_premium, age and vehicle_damage-yes can be considered with relative importance 0.26, 0.125, 0.095, 0.075  respectivly\n",
        "\n",
        "As these 5 main features play a role in decreasing the value of entropy, the machine learning model, random forest classifier considers them closer to the root node."
      ],
      "metadata": {
        "id": "onNXFNBbpiO1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Starting from loading our dataset, we initially checked for null values and duplicates. There were no null values and duplicates so treatment of such was not required. Before data processing, we applied feature scaling techniques to normalize our data to bring all features on the same scale and make it easier to process by ML algorithms.\n",
        "\n",
        "Through Exploratory Data Analysis,\n",
        "\n",
        "Key points:\n",
        "\n",
        "Male customers are more likely to buy the insurance.\n",
        "\n",
        "Customers of age between 30 to 60 are more likely to buy insurance.\n",
        "\n",
        "Customers with Vehicle_Damage are likely to buy insurance.\n",
        "\n",
        "Customers with Driving License have higher chance of buying Insurance.\n",
        "\n",
        "Customers of Region Code 0.28 are buying more in comparison to others.\n",
        "\n",
        "Customers are buying more whose vehicle age in between 1-2 years.\n",
        "\n",
        "Those customers are more likely to buy who are not buy the insurance previously.\n",
        "\n",
        "After that we do hypothesis testing and the assumption of our hypothesis statements are right.\n",
        "\n",
        "The variable 'Age', 'Region_Code', 'Previously_Insured', 'Vehicle_Age', 'Vehicle_Damage', 'Annual_Premium', 'Policy_Sales_Channel','Vehicle_Age_1-2 Year','Vehicle_Age_< 1 Year','Vehicle_Age_> 2 Year' are affecting the target variable. For Feature Selection, we used Variance threshold, Extra tree classifier and correlation heatmap . Here we observed that Previously_Insured and vehicle damage is the most important feature and has the highest impact on the dependent feature and there is no correlation between the two numeric features.\n",
        "\n",
        "Further, we applied Machine Learning Algorithms to determine whether a customer would be interested in Vehicle Insurance. For the LogisticRegression, GaussianNB, AdaBoostClassifier,XGBClassifier algorithm, we got an accuracy score was obtained around 73%-78%. Similarly, for Decision Tree Classifier, BaggingClassifier, LightGBM accuracy score was obtained around 82%-84%. So, we selected our BaggingClassifier as the model with an accuracy score of 84% considering precision and recall as we have an unequal number of observations in each class in our dataset, so accuracy alone can be misleading.\n",
        "\n",
        "That’s it! We reached the end."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}